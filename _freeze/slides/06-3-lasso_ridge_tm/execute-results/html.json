{
  "hash": "6d02338db9c628a7f624e12e11c00fb5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Chapter 6 Part 3\"\nsubtitle: \"tidymodels and shrinkage\"\nformat: \n  revealjs:\n    output-file: \"06-3-lasso_ridge_tm.html\"\n    slide-number: true\n  html:\n    output-file: \"06-3-lasso_ridge_tm_o.html\"\neditor_options: \n  chunk_output_type: console\nlogo: \"img/icon.png\"\n---\n\n\n\n\n## Setup\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(ISLR2)\n```\n:::\n\n\n\n## Lasso and Ridge - Statquest\n\n<https://www.youtube.com/watch?v=Q81RR3yKn30&t=7s> \n\n<https://www.youtube.com/watch?v=NGf0voTMlcs>\n\nOn your own:\n\nRidge Vs Lasso\n<https://www.youtube.com/watch?v=Xm2C_gTAl8c>\n\nElastic Net\n<https://www.youtube.com/watch?v=1dKRdX9bfIo>\n\n\n## Ridge Regression {.small}\n\n:::: columns\n\n::: column\n\n### Pros\n\n* Can be used when $p > n$\n* Can be used to help with multicollinearity\n* Will decrease variance\n(as $\\lambda \\rightarrow \\infty$ )\n\n:::\n\n::: column\n\n### Cons\n\n* Will have increased bias (compared to least squares)\n* Does not really help with variable selection (all variables are included in _some_ regard, even if their $\\beta$ coefficients are really small)\n\n:::\n\n::::\n\n\n\n## Lasso {.small}\n\n:::: columns\n\n::: column\n\n### Pros\n\n* Can be used when $p > n$\n* Can be used to help with multicollinearity\n* Will decrease variance\n(as $\\lambda \\rightarrow \\infty$ )\n* Can be used for variable selection, since it will make some $\\beta$ coefficients exactly 0\n\n:::\n\n::: column\n\n### Cons\n\n* Will have increased bias (compared to least squares)\n* If $p>n$ the lasso can select **at most** $n$ variables\n\n:::\n\n::::\n\n\n\n\n\n\n## What if we want to do both? {.small}\n\n* Elastic net!\n\n* $RSS + \\lambda_1\\sum_{j=1}^p\\beta^2_j+\\lambda_2\\sum_{j=1}^p|\\beta_j|$\n\n. . .\n\n::: question\nWhat is the $\\ell_1$ part of the penalty?\n:::\n\n. . .\n\n::: question\nWhat is the $\\ell_2$ part of the penalty\n:::\n\n\n\n## Elastic net {.small}\n\n$$RSS + \\lambda_1\\sum_{j=1}^p\\beta^2_j+\\lambda_2\\sum_{j=1}^p|\\beta_j|$$\n\n::: question\nWhen will this be equivalent to Ridge Regression?\n:::\n\n\n\n## Elastic net {.small}\n\n$$RSS + \\lambda_1\\sum_{j=1}^p\\beta^2_j+\\lambda_2\\sum_{j=1}^p|\\beta_j|$$\n\n::: question\nWhen will this be equivalent to Lasso?\n:::\n\n\n\n## Elastic Net {.small}\n\n$$RSS + \\lambda_1\\sum_{j=1}^p\\beta^2_j+\\lambda_2\\sum_{j=1}^p|\\beta_j|$$\n\n\n* The $\\ell_1$ part of the penalty will generate a **sparse** model (shrink some $\\beta$ coefficients to exactly 0)\n* The $\\ell_2$ part of the penalty removes the limitation on the number of variables selected (can be $>n$ now)\n\n\n## tidymodels\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_spec <- \n  linear_reg() |> # Pick linear regression\n  set_engine(engine = \"lm\") # set engine\nlm_spec\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear Regression Model Specification (regression)\n\nComputational engine: lm \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_fit <- fit(lm_spec,\n              mpg ~ horsepower,\n              data = Auto)\n```\n:::\n\n\n\n\n\n## Validation set approach {.smaller}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAuto_split <- initial_split(Auto, prop = 0.5)\nAuto_split\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<Training/Testing/Total>\n<196/196/392>\n```\n\n\n:::\n:::\n\n\n\n. . .\n\nExtract the training and testing data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntraining(Auto_split)\ntesting(Auto_split)\n```\n:::\n\n\n\n\n## A faster way! {.smaller}\n\n* You can use `last_fit()` and specify the split\n* This will automatically train the data on the `train` data from the split\n* Instead of specifying which metric to calculate (with `rmse` as before) you can just use `collect_metrics()` and it will automatically calculate the metrics on the `test` data from the split\n\n## A faster way! \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(100000)\n\nAuto_split <- initial_split(Auto, prop = 0.5)\nlm_fit <- last_fit(lm_spec,\n                   mpg ~ horsepower,\n                   split = Auto_split) \n\nlm_fit |>\n  collect_metrics() \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard       4.77  Preprocessor1_Model1\n2 rsq     standard       0.634 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n\n\n\n\n## What about cross validation?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAuto_cv <- vfold_cv(Auto, v = 5)\nAuto_cv\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n#  5-fold cross-validation \n# A tibble: 5 Ã— 2\n  splits           id   \n  <list>           <chr>\n1 <split [313/79]> Fold1\n2 <split [313/79]> Fold2\n3 <split [314/78]> Fold3\n4 <split [314/78]> Fold4\n5 <split [314/78]> Fold5\n```\n\n\n:::\n:::\n\n\n\n\n\n## What if we wanted to do some _preprocessing_ {.smaller}\n\n* For the shrinkage methods we discussed it was important to _scale_ the variables\n\n. . .\n\n\n::: question\n* What would happen if we scale **before** doing cross-validation? Will we get different answers?\n:::\n\n\n\n## What if we wanted to do some _preprocessing_ {.smaller}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAuto_scaled <- Auto |>\n  mutate(horsepower = scale(horsepower))\n\nsd(Auto_scaled$horsepower)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nAuto_cv_scaled <- vfold_cv(Auto_scaled, v = 5)\n\n# Will not actually use:\nmap_dbl(Auto_cv_scaled$splits,\n        function(x) {\n          dat <- as.data.frame(x)$horsepower\n          sd(dat)\n        })\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9698961 1.0060047 0.9967524 1.0339029 0.9922419\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n## What if we wanted to do some _preprocessing_ {.smaller}\n\n* `recipe()`!\n* Using the `recipe()` function along with `step_*()` functions, we can specify _preprocessing_ steps and R will automagically apply them to each fold appropriately.\n\n. . .\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec <- recipe(mpg ~ horsepower, data = Auto) |>\n  step_scale(horsepower) \n```\n:::\n\n\n\n\n* You can find all of the potential preprocessing steps here: <https://tidymodels.github.io/recipes/reference/index.html>\n\n## Where do we plug in this recipe? {.smaller}\n\n* The `recipe` gets plugged into the `fit_resamples()` function\n\n. . .\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAuto_cv <- vfold_cv(Auto, v = 5)\n\nrec <- recipe(mpg ~ horsepower, data = Auto) |>\n  step_scale(horsepower)\n\nresults <- fit_resamples(lm_spec,\n                         preprocessor = rec,\n                         resamples = Auto_cv)\n\nresults |>\n  collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 6\n  .metric .estimator  mean     n std_err .config             \n  <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1 rmse    standard   4.92      5  0.0744 Preprocessor1_Model1\n2 rsq     standard   0.611     5  0.0158 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n\n\n\n\n## What if we want to predict mpg with more variables {.smaller}\n\n* Now we still want to add a step to _scale_ predictors\n* We could either write out all predictors individually to scale them\n* OR we could use the `all_predictors()` short hand.\n\n. . .\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec <- recipe(mpg ~ horsepower + displacement + weight, data = Auto) |>\n  step_scale(all_predictors())\n```\n:::\n\n\n\n\n\n## Putting it together  {.smaller}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec <- recipe(mpg ~ horsepower + displacement + weight, data = Auto) |>\n  step_scale(all_predictors())\n\nresults <- fit_resamples(lm_spec,\n                         preprocessor = rec,\n                         resamples = Auto_cv)\n\nresults |>\n  collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 6\n  .metric .estimator  mean     n std_err .config             \n  <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1 rmse    standard   4.23      5  0.157  Preprocessor1_Model1\n2 rsq     standard   0.704     5  0.0253 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n\n\n## {{< fa laptop >}} `Application Exercise` {.smaller}\n\n::: nonincremental\n\n1. Examine the `Hitters` dataset by running `?Hitters` in the Console\n2. We want to predict a major league player's `Salary` from all of the other 19 variables in this dataset. Create a visualization of `Salary`.\n3. Create a recipe to estimate this model.\n4. Add a preprocessing step to your recipe, scaling each of the predictors\n\n:::\n\n\n\n## What if we have categorical variables?\n\n* We can turn the categorical variables into indicator (\"dummy\") variables in the recipe\n\n. . .\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec <- recipe(mpg ~ horsepower + displacement + weight, data = Auto) |>\n  step_dummy(all_nominal()) |>\n  step_scale(all_predictors())\n```\n:::\n\n\n\n## What if we have missing data?\n\n* We can remove any rows with missing data\n\n. . .\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec <- recipe(mpg ~ horsepower + displacement + weight, data = Auto) |>\n  step_dummy(all_nominal()) |>\n  step_naomit(everything()) |>\n  step_scale(all_predictors())\n```\n:::\n\n\n\n\n## What if we have missing data?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec <- recipe(mpg ~ horsepower + displacement + weight, data = Auto) |>\n  step_dummy(all_nominal()) |>\n  step_naomit(all_outcomes()) |>\n  step_impute_mean(all_predictors()) |>\n  step_scale(all_predictors())\n```\n:::\n\n\n\n## {{< fa laptop >}} `Application Exercise` {.smaller}\n\n::: nonincremental\n\n1. Add a preprocessing step to your recipe to convert nominal variables into indicators\n2. Add a step to your recipe to remove missing values for the outcome\n3. Add a step to your recipe to impute missing values for the predictors using the average for the remaining values **NOTE THIS IS NOT THE BEST WAY TO DO THIS!**\n\n\n:::\n\n\n## Ridge, Lasso, and Elastic net  {.smaller}\n\nWhen specifying your model, you can indicate whether you would like to use ridge, lasso, or elastic net. We can write a general equation to minimize:\n\n$$RSS + \\lambda\\left((1-\\alpha)\\sum_{i=1}^p\\beta_j^2+\\alpha\\sum_{i=1}^p|\\beta_j|\\right)$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_spec <- linear_reg() |>\n  set_engine(\"glmnet\") \n```\n:::\n\n\n\n* First specify the engine. We'll use `glmnet`\n* The `linear_reg()` function has two additional parameters, `penalty` and `mixture`\n* `penalty` is $\\lambda$ from our equation. \n* `mixture` is a number between 0 and 1 representing $\\alpha$\n\n## Ridge, Lasso, and Elastic net {.small}\n\n\n$$RSS + \\lambda\\left((1-\\alpha)\\sum_{i=1}^p\\beta_j^2+\\alpha\\sum_{i=1}^p|\\beta_j|\\right)$$\n\n\n::: question\nWhat would we set `mixture` to in order to perform Ridge regression?\n:::\n\n. . .\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nridge_spec <- linear_reg(penalty = 100, mixture = 0) |> \n  set_engine(\"glmnet\") \n```\n:::\n\n\n\n\n## {{< fa laptop >}} `Application Exercise` {.small}\n\n::: nonincremental\n\n1. Set a seed `set.seed(1)`\n2. Create a cross validation object for the `Hitters` dataset\n3. Using the recipe from the previous exercise, fit the model using Ridge regression with a penalty $\\lambda$ = 300\n4. What is the estimate of the test RMSE for this model?\n\n:::\n\n\n## Ridge, Lasso, and Elastic net\n\n\n$$RSS + \\lambda\\left((1-\\alpha)\\sum_{i=1}^p\\beta_j^2+\\alpha\\sum_{i=1}^p|\\beta_j|\\right)$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nridge_spec <- linear_reg(penalty = 100, mixture = 0) |> \n  set_engine(\"glmnet\") \n```\n:::\n\n\n\n. . .\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlasso_spec <- linear_reg(penalty = 5, mixture = 1) |>\n  set_engine(\"glmnet\") \n```\n:::\n\n\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\nenet_spec <- linear_reg(penalty = 60, mixture = 0.7) |> \n  set_engine(\"glmnet\") \n```\n:::\n\n\n\n\n\n## Okay, but we wanted to look at 3 different models! {.small}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nridge_spec <- linear_reg(penalty = 100, mixture = 0) |>\n  set_engine(\"glmnet\") \n\nresults <- fit_resamples(ridge_spec,\n                         preprocessor = rec,\n                         resamples = Auto_cv)\n```\n:::\n\n\n\n\n\n. . .\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlasso_spec <- linear_reg(penalty = 5, mixture = 1) |>\n  set_engine(\"glmnet\") \n\nresults <- fit_resamples(lasso_spec,\n                         preprocessor = rec,\n                         resamples = Auto_cv)\n```\n:::\n\n\n\n. . .\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nelastic_spec <- linear_reg(penalty = 40, mixture = 0.1) |>\n  set_engine(\"glmnet\") \n\nresults <- fit_resamples(elastic_spec,\n                         preprocessor = rec,\n                         resamples = Auto_cv)\n```\n:::\n\n\n\n* ðŸ˜± this looks like copy + pasting!\n\n\n\n## tune ðŸŽ¶\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenalty_spec <- \n  linear_reg(penalty = tune(), mixture = tune()) |> \n  set_engine(\"glmnet\") \n```\n:::\n\n\n\n\n* Notice the code above has `tune()` for the the penalty and the mixture. Those are the things we want to vary!\n\n\n\n##  tune ðŸŽ¶ {.small}\n\n* Now we need to create a grid of potential penalties ( $\\lambda$ ) and mixtures ( $\\alpha$ ) that we want to test\n* Instead of `fit_resamples()` we are going to use `tune_grid()`\n\n. . .\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid <- expand_grid(penalty = seq(0, 100, by = 10),\n                    mixture = seq(0, 1, by = 0.25))\n\nresults <- tune_grid(penalty_spec,\n                     preprocessor = rec,\n                     grid = grid, \n                     resamples = Auto_cv)\n```\n:::\n\n\n\n##  tune autoplot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(results)+ ## ggplot function\n  theme_classic()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in ggplot2::scale_x_continuous(trans = trans): log-10 transformation introduced infinite values.\nlog-10 transformation introduced infinite values.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](06-3-lasso_ridge_tm_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\n\n\n## tune ðŸŽ¶ {.small}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults |>\n  collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 110 Ã— 8\n   penalty mixture .metric .estimator  mean     n std_err .config              \n     <dbl>   <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n 1       0       0 rmse    standard   4.25      5  0.139  Preprocessor1_Model01\n 2       0       0 rsq     standard   0.702     5  0.0231 Preprocessor1_Model01\n 3      10       0 rmse    standard   4.75      5  0.119  Preprocessor1_Model02\n 4      10       0 rsq     standard   0.697     5  0.0211 Preprocessor1_Model02\n 5      20       0 rmse    standard   5.30      5  0.0981 Preprocessor1_Model03\n 6      20       0 rsq     standard   0.697     5  0.0210 Preprocessor1_Model03\n 7      30       0 rmse    standard   5.71      5  0.0850 Preprocessor1_Model04\n 8      30       0 rsq     standard   0.697     5  0.0209 Preprocessor1_Model04\n 9      40       0 rmse    standard   6.02      5  0.0775 Preprocessor1_Model05\n10      40       0 rsq     standard   0.697     5  0.0209 Preprocessor1_Model05\n# â„¹ 100 more rows\n```\n\n\n:::\n:::\n\n\n\n\n\n## Subset results {.small}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults |>\n  collect_metrics() |>\n  filter(.metric == \"rmse\") |>\n  arrange(mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 55 Ã— 8\n   penalty mixture .metric .estimator  mean     n std_err .config              \n     <dbl>   <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n 1       0    1    rmse    standard    4.23     5  0.157  Preprocessor1_Model45\n 2       0    0.75 rmse    standard    4.23     5  0.156  Preprocessor1_Model34\n 3       0    0.25 rmse    standard    4.23     5  0.155  Preprocessor1_Model12\n 4       0    0.5  rmse    standard    4.23     5  0.156  Preprocessor1_Model23\n 5       0    0    rmse    standard    4.25     5  0.139  Preprocessor1_Model01\n 6      10    0    rmse    standard    4.75     5  0.119  Preprocessor1_Model02\n 7      20    0    rmse    standard    5.30     5  0.0981 Preprocessor1_Model03\n 8      10    0.25 rmse    standard    5.60     5  0.0861 Preprocessor1_Model13\n 9      30    0    rmse    standard    5.71     5  0.0850 Preprocessor1_Model04\n10      40    0    rmse    standard    6.02     5  0.0775 Preprocessor1_Model05\n# â„¹ 45 more rows\n```\n\n\n:::\n:::\n\n\n\n* Since this is a data frame, we can do things like filter and arrange!\n\n## Subset results {.small}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults |>\n  collect_metrics() |>\n  filter(.metric == \"rmse\") |>\n  arrange(mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 55 Ã— 8\n   penalty mixture .metric .estimator  mean     n std_err .config              \n     <dbl>   <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n 1       0    1    rmse    standard    4.23     5  0.157  Preprocessor1_Model45\n 2       0    0.75 rmse    standard    4.23     5  0.156  Preprocessor1_Model34\n 3       0    0.25 rmse    standard    4.23     5  0.155  Preprocessor1_Model12\n 4       0    0.5  rmse    standard    4.23     5  0.156  Preprocessor1_Model23\n 5       0    0    rmse    standard    4.25     5  0.139  Preprocessor1_Model01\n 6      10    0    rmse    standard    4.75     5  0.119  Preprocessor1_Model02\n 7      20    0    rmse    standard    5.30     5  0.0981 Preprocessor1_Model03\n 8      10    0.25 rmse    standard    5.60     5  0.0861 Preprocessor1_Model13\n 9      30    0    rmse    standard    5.71     5  0.0850 Preprocessor1_Model04\n10      40    0    rmse    standard    6.02     5  0.0775 Preprocessor1_Model05\n# â„¹ 45 more rows\n```\n\n\n:::\n:::\n\n\n\n::: question\nWhich would you choose?\n:::\n\n\n\n## {.small}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresults |>\n  collect_metrics() |>\n  filter(.metric == \"rmse\") |>\n  ggplot(aes(penalty, mean, color = factor(mixture), group = factor(mixture))) +\n  geom_line() +\n  geom_point() + \n  labs(y = \"RMSE\")\n```\n\n::: {.cell-output-display}\n![](06-3-lasso_ridge_tm_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](06-3-lasso_ridge_tm_files/figure-html/mtcars-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\n## {{< fa laptop >}} `Application Exercise` {.small}\n\n::: small\n::: nonincremental\n\n1. Using the `Hitters` cross validation object and recipe created in the previous exercise, use `tune_grid` to pick the optimal penalty and mixture values.\n2. Update the code below to create a grid that includes penalties from 0 to 50 by 1 and mixtures from 0 to 1 by 0.5.\n3. Use this grid in the `tune_grid` function. Then use `collect_metrics` and filter to only include the RSME estimates.\n4. Create a figure to examine the estimated test RMSE for the grid of penalty and mixture values -- which should you choose?\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrid <- expand_grid(penalty = seq(0, ----),\n                    mixture = seq(0, 1, by = ----))\n```\n:::\n\n\n\n\n## Putting it all together {.small}\n\n* Often we can use a combination of all of these tools together\n* First split our data\n* Do cross validation on _just the training data_ to tune the parameters\n* Use `last_fit()` with the selected parameters, specifying the split data so that it is evaluated on the left out test sample\n\n\n\n## Putting it all together {.small}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nauto_split <- initial_split(Auto, prop = 0.5)\nauto_train <- training(auto_split)\nauto_cv <- vfold_cv(auto_train, v = 5)\n\nrec <- recipe(mpg ~ horsepower + displacement + weight, data = auto_train) |>\n  step_scale(all_predictors())\n\ntuning <- tune_grid(penalty_spec,\n                     rec,\n                     grid = grid,\n                     resamples = auto_cv)\n\ntuning |>\n  collect_metrics() |>\n  filter(.metric == \"rmse\") |>\n  arrange(mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 55 Ã— 8\n   penalty mixture .metric .estimator  mean     n std_err .config              \n     <dbl>   <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n 1       0    1    rmse    standard    3.49     5   0.214 Preprocessor1_Model45\n 2       0    0.75 rmse    standard    3.50     5   0.207 Preprocessor1_Model34\n 3       0    0.5  rmse    standard    3.51     5   0.206 Preprocessor1_Model23\n 4       0    0.25 rmse    standard    3.51     5   0.206 Preprocessor1_Model12\n 5       0    0    rmse    standard    3.57     5   0.220 Preprocessor1_Model01\n 6      10    0    rmse    standard    4.22     5   0.229 Preprocessor1_Model02\n 7      20    0    rmse    standard    4.80     5   0.227 Preprocessor1_Model03\n 8      10    0.25 rmse    standard    5.13     5   0.228 Preprocessor1_Model13\n 9      30    0    rmse    standard    5.21     5   0.227 Preprocessor1_Model04\n10      40    0    rmse    standard    5.50     5   0.227 Preprocessor1_Model05\n# â„¹ 45 more rows\n```\n\n\n:::\n:::\n\n\n\n\n\n## Putting it all together {.small}\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_spec <- linear_reg(penalty = 0, mixture = 0) |>\n  set_engine(\"glmnet\")\nfit <- last_fit(final_spec, \n                rec,\n                split = auto_split) \nfit |>\n  collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard       4.94  Preprocessor1_Model1\n2 rsq     standard       0.681 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n\n\n## Extracting coefficients {.small}\n\n* We can use `workflow()` to combine the recipe and the model specification to pass to a `fit` object.\n\n. . .\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntraining_data <- training(auto_split)\n\nworkflow() |>\n  add_recipe(rec) |>\n  add_model(final_spec) |>\n  fit(data = training_data) |>\n  tidy()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 Ã— 3\n  term         estimate penalty\n  <chr>           <dbl>   <dbl>\n1 (Intercept)    41.4         0\n2 horsepower     -0.814       0\n3 displacement   -1.42        0\n4 weight         -3.83        0\n```\n\n\n:::\n:::\n\n\n\n## {{< fa laptop >}} `Application Exercise` {.small}\n\n::: small\n::: nonincremental\n\n1. Using the final model specification, extract the coefficients from the model by creating a `workflow`\n2. Filter out any coefficients exactly equal to 0\n:::\n:::\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}