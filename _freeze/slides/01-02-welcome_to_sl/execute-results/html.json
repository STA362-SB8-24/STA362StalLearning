{
  "hash": "4ed9dba31a726430993a76fde84e3638",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Chapter 1 and 2\"\nformat: \n  revealjs:\n    echo: false\n    message: false\n    warning: false\n---\n\n\n\n\n\n# Intro and Chapter 1\n\n## üëã\n\n###  Tyler George\n\n<i class=\"fa fa-envelope\"></i> &nbsp; [{{< var instructor.email >}}](mailto:{{< var instructor.email >}})\n\n<i class=\"fa fa-calendar\"></i> &nbsp; {{< var instructor.officehrs >}}\n\n\n\n## Course Website\n\n[{{< var course.url >}}]({{< var course.url >}})\n\n## Intros\n\n- Name\n- Major\n- Fun OR boring fact \n\n\n## Statistical Learning Problems {.small}\n\n:::: {.columns}\n::: {.column}\n\n- Identify risk factors for breast cancer\n:::\n\n::: {.column}\n\n![](img/01/breast-cancer.jpg)\n:::\n::::\n\n::: footer\n{{< var instructor.name >}} _adapted from slides by Hastie & Tibshirani_\n:::\n\n\n## Statistical Learning Problems {.small}\n\n:::: {.columns}\n\n::: {.column}\n\n- Customize an email spam detection system\n\n:::\n::: {.column}\n\n* **Data**: 4601 labeled emails sent to _George_ who works at _HP Labs_ \n* **Input features**: frequencies of words and punctuation\n\n:::\n::::\n\n---| george | you | hp | free | ! | edu | remove\n--|-----|-----|----|-----|-----|----|------\n**spam** | 0.00 | 2.26 | 0.02 | 0.52 | 0.51 | 0.01 | 0.28\n**email** | 2.27 | 1.27 | 0.90 | 0.07 | 0.11 | 0.29 | 0.01\n\n::: footer\n{{< var instructor.name >}} _adapted from slides by Hastie & Tibshirani_\n:::\n\n\n\n## Statistical Learning Problems {.small}\n\n:::: {.columns}\n::: {.column}\n- Identify numbers in handwritten zip code  \n:::\n\n::: {.column}\n![](img/01/zipcode.png)\n:::\n\n::::\n\n::: footer\n{{< var instructor.name >}} _adapted from slides by Hastie & Tibshirani_\n:::\n\n## Statistical Learning Problems {.small}\n\n:::: {.columns}\n\n::: {.column}\nEstablish the relationship between variables in population survey data  \n:::\n\n::: {.column}\nIncome survey data for males from the central Atlantic region of US, 2009\n\n\n![](img/01/wage1.png)\n\n:::\n\n::::\n\n::: footer\n{{< var instructor.name >}} _adapted from slides by Hastie & Tibshirani_\n:::\n\n\n# Statistical Learning Problems {.small}\n\n:::: {.columns}\n\n::: {.column}\n- Classify pixels of an image\n:::\n\n\n::: {.column}\n<img src = \"img/01/land-use.png\" height = 300></img>\n\nUsage $\\in$ {red soil, cotton, vegetation stubble, mixture, gray soil, damp\ngray soil}\n:::\n\n::::\n\n::: footer\n{{< var instructor.name >}} _adapted from slides by Hastie & Tibshirani_\n::: \n\n\n\n## ‚úåÔ∏è types of statistical learning\n\n\n- Supervised Learning\n\n- Unsupervised Learning\n\n\n## Supervised Learning {.small}\n\n::: footer\n{{< var instructor.name >}} _adapted from slides by Hastie & Tibshirani_\n:::\n\n> * **outcome variable**: $Y$, (dependent variable,\nresponse, target)\n> * **predictors**: vector of $p$ predictors, $X$, (inputs,\nregressors, covariates, features, independent variables)\n> * In the **regression problem**, $Y$ is quantitative (e.g price,\nblood pressure)\n> * In the **classification** problem, $Y$ takes values in a finite,\nunordered set (survived/died, digit 0-9, cancer class of\ntissue sample)\n> * We have **training data** $(x_1, y_1), \\dots, (x_N, y_N)$. These are\nobservations (examples, instances) of these measurements\n\n\n## Supervised Learning\n\n::: .question\nWhat do you think are some objectives here?\n:::\n\n### Objectives\n\n- Accurately predict unseen test cases\n- Understand which inputs affect the outcome, and how\n- Assess the quality of our predictions and inferences\n\n::: footer\n{{< var instructor.name >}} _adapted from slides by Hastie & Tibshirani_\n:::\n\n\n## Unsupervised Learning {.small}\n\n::: footer\n{{< var instructor.name >}} _adapted from slides by Hastie & Tibshirani_\n:::\n\n> * No outcome variable, just a set of predictors (features)\nmeasured on a set of samples\n> * objective is more fuzzy -- find groups of samples that\nbehave similarly, find features that behave similarly, find\nlinear combinations of features with the most variation\n> * difficult to know how well your are doing\n> * different from supervised learning, but can be useful as a\npre-processing step for supervised learning\n\n\n## Let's take a tour - class website {.small}\n\n:::: {.columns}\n\n::: {.column}\n![](img/demo.png)\n:::\n\n\n::: {.column}\n\n- Concepts introduced:\n  - How to find slides\n  - How to find assignments\n  - How to find RStudio\n  - How to get help\n  - How to find policies\n  \n:::\n\n::::\n\n\n# Chapter 2 - Statistical Learning\n\n\n## Regression and Classification\n\n- Regression: quantitative response\n- Classification: qualitative (categorical) response\n\n\n## Regression and Classification\n\n::: question\nWhat would be an example of a **regression** problem?\n:::\n\n- Regression: quantitative response\n- Classification: qualitative (categorical) response\n\n\n\n\n## Regression and Classification\n\n::: question\nWhat would be an example of a **classification** problem?\n:::\n\n- Regression: quantitative response\n- Classification: qualitative (categorical) response\n\n\n# Regression {.center}\n\n## Auto data {.smaller}\n\n::: center\n\n\n\n:::\n\nAbove are `mpg` vs `horsepower`, `weight`, and `acceleration`, with a blue linear-regression line fit separately to each. Can we predict `mpg` using these three?\n\n. . .\n\nMaybe we can do better using a model:\n\n$$\\texttt{mpg} \\approx f(\\texttt{horsepower}, \\texttt{weight}, \\texttt{acceleration})$$\n\n\n\n## Notation {.smaller}\n\n> * `mpg` is the **response** variable, the **outcome** variable, we refer to this as $Y$\n> * `horsepower` is a **feature**, **input**, **predictor**, we refer to this as $X_1$\n> * `weight` is $X_2$\n> * `acceleration` is $X_3$\n> * Our **input vector** is:\n>    * $X = \\begin{bmatrix} X_1 \\\\X_2 \\\\X_3\\end{bmatrix}$ \n> * Our **model** is  \n>    * $Y = f(X) + \\varepsilon$\n* $\\varepsilon$ is our error\n\n\n\n## Why do we care about $f(X)$? {.small}\n\n> * We can use $f(X)$ to make predictions of $Y$ for new values of $X = x$\n> * We can gain a better understanding of which components of $X = (X_1, X_2, \\dots, X_p)$ are important for explaining $Y$\n> * Depending on how complex $f$ is, maybe we can understand how each component ( $X_j$ ) of $X$ affects $Y$\n\n\n## How do we choose $f(X)$? {.small}\n\n\n\n\n\nWhat is a good value for $f(X)$ at any selected value of $X$, say $X = 100$? There can be many $Y$ values at $X = 100$. \n\n## How do we choose $f(X)$? {.small}\n\n\n\n\n\nWhat is a good value for $f(X)$ at any selected value of $X$, say $X = 100$? There can be many $Y$ values at $X = 100$. \n\n\n## How do we choose $f(X)$? {.small}\n\n\n\n\n\nWhat is a good value for $f(X)$ at any selected value of $X$, say $X = 100$? There can be many $Y$ values at $X = 100$. \n\n\n> * There are 17 points here, what value should I choose for f(100). What do you think the blue dot represents?\n\n## How do we choose $f(X)$? {.small}\n\n\n\n\n\nA good value is\n\n$$f(100) = E(Y|X = 100)$$\n\n. . .\n\n$E(Y|X = 100)$ means **expected value** (average) of $Y$ given $X = 100$\n\n. . .\n\nThis ideal $f(x) = E(Y | X = x)$ is called the **regression function**\n\n\n\n## Regression function, $f(X)$\n\n* Also works or a vector, $X$, for example,\n\n$$f(x) = f(x_1, x_2, x_3) = E[Y | X_1 = x_1, X_2 = x_2, X_3 = x_3]$$\n\n* This is the **optimal** predictor of $Y$ in terms of **mean-squared prediction error**\n\n## Regression function, $f(X)$\n\n::: definition\n$f(x) = E(Y|X = x)$ is the function that **minimizes** $E[(Y - g(X))^2 |X = x]$ over all\nfunctions $g$ at all points $X = x$\n:::\n\n> * $\\varepsilon = Y - f(x)$ is the **irreducible error** \n> * even if we knew $f(x)$, we would still make errors in prediction, since at each $X = x$ there is typically a distribution of possible $Y$ values\n\n## Regression function, $f(X)$ {.small}\n\n\n\n\n\n\n## Regression function, $f(X)$ {.small}\n\n\n\n\n\n\n\n::: question\nUsing these points, how would I calculate the **regression function**?\n:::\n\n. . .\n\n* Take the average! $f(100) = E[\\texttt{mpg}|\\texttt{horsepower} = 100] = 19.6$\n\n## Regression function, $f(X)$ {.small}\n\n\n\n\n\n::: question\nThis point has a $Y$ value of 32.9. What is $\\hat\\varepsilon$?\n:::\n\n\n> * $\\hat\\varepsilon = Y - \\hat{f}(X) = 32.9 - 19.6 = \\color{red}{13.3}$\n\n\n\n## The error {.smaller}\n\nFor any estimate, $\\hat{f}(x)$, of $f(x)$, we have\n\n$$E[(Y - \\hat{f}(x))^2 | X = x] = \\underbrace{[f(x) - \\hat{f}(x)]^2}_{\\textrm{reducible error}} + \\underbrace{Var(\\varepsilon)}_{\\textrm{irreducible error}}$$\n\n> * Assume for a moment that both $\\hat{f}$ and X are fixed.\n> * $E(Y ‚àí \\hat{Y})^2$ represents the average, or expected value, of the squared difference between the predicted and actual value of Y, and Var( $\\varepsilon$ ) represents the variance associated with the error term\n> * The focus of this class is on techniques for estimating f with the aim of minimizing the **reducible error**. \n> * the **irreducible error** will always provide an upper bound on the accuracy of our prediction for Y\n* This bound is almost always unknown in practice\n\n\n## Estimating $f$ {.smaller}\n\n* Typically we have very few (if any!) data points at $X=x$ exactly, so we cannot compute $E[Y|X=x]$\n* For example, what if we were interested in estimating miles per gallon when horsepower was 104.\n\n::: center\n\n\n\n\n\n:::\n\n. . .\n\nüí° We can _relax_ the definition and let\n\n$$\\hat{f}(x) = E[Y | X\\in \\mathcal{N}(x)]$$\n\n> * Where $\\mathcal{N}(x)$ is some **neighborhood** of $x$\n\n\n## Notation pause!\n\n<br><br><br>\n\n$$\\hat{f}(x) = \\underbrace{E}_{\\textrm{The expectation}}[\\underbrace{Y}_{\\textrm{of Y}} \\underbrace{|}_{\\textrm{given}} \\underbrace{X\\in \\mathcal{N}(x)}_{\\textrm{X is in the neighborhood of x}}]$$\n\n. . .\n\n::: question\nüö® If you need a notation pause at any point during this class, please let me know! \n:::\n\n\n## Estimating $f$ {.small}\n\nüí° We can _relax_ the definition and let\n\n$$\\hat{f}(x) = E[Y | X\\in \\mathcal{N}(x)]$$\n\n> * Nearest neighbor averaging does pretty well with small $p$ ( $p\\leq 4$ ) and large $n$\n> * Nearest neighbor is _not great_ when $p$ is large because of the **curse of dimensionality** (because nearest neighbors tend to be far away in high dimensions)\n\n. . .\n\n::: question\nWhat do I mean by $p$? What do I mean by $n$?\n:::\n\n\n\n## Parametric models {.small}\n\nA common parametric model is a **linear** model\n\n$$f(X) = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\dots + \\beta_pX_p$$\n\n> * A linear model has $p + 1$ parameters ( $\\beta_0,\\dots,\\beta_p$ )\n> * We estimate these parameters by **fitting** a model to **training** data\n> * Although this model is _almost never correct_ it can often be a good interpretable approximation to the unknown true function, $f(X)$\n\n\n\n# Let's look at a simulated example {.center}\n\n\n## {.small}\n\n<center>\n<img src = \"img/03/sim1.png\" height = \"400\"> </img>\n</center>\n\n* The <font color = \"red\"> red </font> points are simulated values for `income` from the model:\n\n$$\\texttt{income} = f(\\texttt{education, senority}) + \\varepsilon$$\n\n* $f$ is the <font color = \"blue\"> blue </font> surface\n\n## {.small}\n\n<center>\n<img src = \"img/03/sim2.png\" height = \"400\"> </img>\n</center>\n\nLinear regression model fit to the simulated data\n\n$$\\hat{f}_L(\\texttt{education, senority}) = \\hat{\\beta}_0 + \\hat{\\beta}_1\\texttt{education}+\\hat{\\beta}_2\\texttt{senority}$$\n\n## {.small}\n\n<center>\n<img src = \"img/03/sim3.png\" height = \"400\"> </img>\n</center>\n\n* More flexible regression model $\\hat{f}_S(\\texttt{education, seniority})$ fit to the simulated data. \n* Here we use a technique called a **thin-plate spline** to fit a flexible surface\n\n## {.small}\n\n<center>\n<img src = \"img/03/sim4.png\" height = \"400\"> </img>\n</center>\n\nAnd even **MORE flexible** üò± model $\\hat{f}(\\texttt{education, seniority})$. \n\n* Here we've basically drawn the surface to hit every point, minimizing the error, but completely **overfitting**\n\n\n \n## ü§π Finding balance {.small}\n\n> * **Prediction accuracy** versus **interpretability**\n> * Linear models are easy to interpret, thin-plate splines\nare not\n> * Good fit versus **overfit** or **underfit**\n> * How do we know when the fit is just right?\n> * **Parsimony** versus **black-box**\n> * We often prefer a simpler model involving fewer variables over a black-box predictor involving them all\n\n##\n\n![](img/03/flex.png)\n\n\n\n## Accuracy {.small}\n\n* We've fit a model $\\hat{f}(x)$ to some `training data`.\n\n* We can measure **accuracy** as the average squared prediction error over that `train` data\n\n$$MSE_{\\texttt{train}} = \\textrm{Ave}_{train}[y_i-\\hat{f}(x_i)]^2$$\n\n. . .\n\n::: question\nWhat can go wrong here? \n:::\n\n\n> * This may be biased towards **overfit** models\n\n\n\n## Accuracy\n\n\n\n\n\n\n::: question\nI have some `train` data, plotted above. What $\\hat{f}(x)$ would minimize the $MSE_{\\texttt{train}}$?\n:::\n\n$$MSE_{\\texttt{train}} = \\textrm{Ave}_{train}[y_i-\\hat{f}(x_i)]^2$$\n\n\n\n## Accuracy \n\n\n\n\n\n::: question\nI have some `train` data, plotted above. What $\\hat{f}(x)$ would minimize the $MSE_{\\texttt{train}}$?\n:::\n\n$$MSE_{train} = \\textrm{Ave}_{i\\in\\texttt{train}}[y_i-\\hat{f}(x_i)]^2$$\n\n\n\n## Accuracy \n\n\n\n\n\n::: question\nWhat is wrong with this?\n:::\n\n. . .\n\nIt's **overfit!**\n\n\n\n## Accuracy\n\n\n\n\n\nIf we get a new sample, that overfit model is probably going to be terrible!\n\n\n## Accuracy\n\n* We've fit a model $\\hat{f}(x)$ to some `training data`.\n* Instead of measuring **accuracy** as the average squared prediction error over that `train` data, we can compute it using fresh `test` data.\n\n$$MSE_{\\texttt{test}} = \\textrm{Ave}_{test}[y_i-\\hat{f}(x_i)]^2$$\n\n##\n\n![](img/03/mse1.png)\n\nBlack curve is the \"truth\" on the left. <font color=\"red\"> Red </font> curve on right is $MSE_{\\texttt{test}}$, <font color=\"grey\">grey </font>curve is $MSE_{\\texttt{train}}$. <font color=\"orange\">Orange</font>, <font color=\"blue\">blue </font>and <font color=\"green\">green </font>curves/squares correspond to fis of different flexibility.\n\n##\n\n![](img/03/mse2.png)\n\nHere the truth is smoother, so the smoother fit and linear model do\nreally well\n\n##\n\n![](img/03/mse3.png)\n\nHere the truth is wiggly and the noise is low, so the more flexible fits do the best\n\n\n## Bias-variance trade-off {.small}\n\n> * We've fit a model, $\\hat{f}(x)$, to some training data\n> * Let's pull a test observation from this population ( $x_0, y_0$ )\n> * The _true_ model is $Y = f(x) + \\varepsilon$\n> * $f(x) = E[Y|X=x]$\n\n. . .\n\n$$E(y_0 - \\hat{f}(x_0))^2 = \\textrm{Var}(\\hat{f}(x_0)) + [\\textrm{Bias}(\\hat{f}(x_0))]^2 + \\textrm{Var}(\\varepsilon)$$\n\n. . .\n\nThe expectation averages over the variability of $y_0$ as well as the variability of the training data. $\\textrm{Bias}(\\hat{f}(x_0)) =E[\\hat{f}(x_0)]-f(x_0)$\n\n> * As **flexibility** of $\\hat{f}$ $\\uparrow$, its variance $\\uparrow$ and its bias $\\downarrow$\n> * choosing the flexibility based on average test error amounts to a **bias-variance trade-off**\n\n::: notes\n\n* That U-shape we see for the test MSE curves is due to this bias-variance trade-off\n* The expected test MSE for a given $x_0$ can be decomposed into three components: the **variance** of $\\hat{f}(x_o)$, the squared **bias** of $\\hat{f}(x_o)$ and t4he variance of the error term $\\varepsilon$\n* Here the notation $E[y_0 ‚àí \\hat{f}(x_0)]^2$ defines the expected test MSE, and refers to the average test MSE that we would obtain if we repeatedly estimated $f$ using a large number of training sets, and tested each at $x_0$\n* The overall expected test MSE can be computed by averaging  $E[y_0 ‚àí \\hat{f}(x_0)]^2$ over all possible values of $x_0$ in the test set.\n* SO we want to minimize the expected test error, so to do that we need to pick a statistical learning method to simultenously acheive low bias and low variance. \n* Since both of these quantities are non-negative, the expected test MSE can never fall below Var( $\\varepsilon$ )\n:::\n\n## Bias-variance trade-off\n\n![](img/03/bias-var.png)\n\n## Conceptual Idea\n\nWatch StatQuest video: [Machine Learning Fundamentals: Bias and Variance](https://www.youtube.com/watch?v=EuBBz3bI-aA)\n\n# Classification {.center}\n\n\n## Notation\n\n> * $Y$ is the response variable. It is **qualitative**\n> * $\\mathcal{C}(X)$ is the classifier that assigns a class $\\mathcal{C}$ to some future unlabeled observation, $X$\n> * Examples:\n    * Email can be classified as $\\mathcal{C}=(\\texttt{spam, not spam})$\n    * Written number is one of $\\mathcal{C}=\\{0, 1, 2, \\dots, 9\\}$\n\n\n\n## Classification Problem\n\n::: question\nWhat is the goal?\n:::\n\n\n> * Build a classifier $\\mathcal{C}(X)$ that assigns a class label from $\\mathcal{C}$ to a future unlabeled observation $X$  \n> * Assess the uncertainty in each classification  \n> * Understand the roles of the different predictors among $X = (X_1, X_2, \\dots, X_p)$\n\n\n## {.small}\n\n<center>\n<img src = \"img/03/class1.png\" height = 275></img>\n</center>\n\nSuppose there are $K$ elements in $\\mathcal{C}$, numbered $1, 2, \\dots, K$\n\n$$p_k(x) = P(Y = k|X=x), k = 1, 2, \\dots, K$$\nThese are **conditional class probabilities** at $x$\n\n. . .\n\n::: question\nHow do you think we could calculate this?\n:::\n\n. . .\n\n* In the plot, you could examine the mini-barplot at $x = 5$\n\n\n## {.small}\n\n<center>\n<img src = \"img/03/class1.png\" height = 275></img>\n</center>\n\nSuppose there are $K$ elements in $\\mathcal{C}$, numbered $1, 2, \\dots, K$\n\n$$p_k(x) = P(Y = k|X=x), k = 1, 2, \\dots, K$$\nThese are **conditional class probabilities** at $x$\n\n* The **Bayes optimal classifier** at $x$ is\n\n$$\\mathcal{C}(x) = j \\textrm{ if } p_j(x) = \\textrm{max}\\{p_1(x), p_2(x), \\dots, p_K(x)\\}$$\n\n::: notes\n\n* Notice that probability is a **conditional** probability \n* It is the probability that Y equals k given the observed preditor vector, $x$ \n* Let's say we were using a Bayes Classifier for a two class problem, Y is 1 or 2. We would predict that the class is one if $P(Y=1|X=x_0)>0.5$ and 2 otherwise\n:::\n\n## {.small}\n\n<center>\n<img src = \"img/03/class2.png\" height = 275></img>\n</center>\n\n::: question\nWhat if this was our data and there were no points at exactly $x = 5$? Then how could we calculate this?\n:::\n\n> * Nearest neighbor like before!\n> * This does break down as the dimensions grow, but the impact of $\\mathcal{\\hat{C}}(x)$ is less than on $\\hat{p}_k(x), k = 1,2,\\dots,K$\n\n\n\n## Accuracy {.smaller}\n\n* Misclassification error rate\n\n$$Err_{\\texttt{test}} = \\frac{\\#correct predictions}{total predictions} = \\textrm{Ave}_{test}I[y_i\\neq \\mathcal{\\hat{C}}(x_i)]$$\n> * $I(\\cdot)$ is an indicator function and will only be eitehr 0 or 1.\n\n> * The **Bayes Classifier** using the true $p_k(x)$ has the smallest error\n> * Some of the methods we (may) learn build structured models for $\\mathcal{C}(x)$ (support vector machines, for example)\n> * Some build structured models for $p_k(x)$ (logistic regression, for example)\n\n::: notes\n\n* the test error rate $\\textrm{Ave}_{i\\in\\texttt{test}}I[y_i\\neq \\mathcal{\\hat{C}}(x_i)]$ is minimized on average by very simple classifier that assigns each observation to the most likely class, given its predictor values (that's the Bayes classifier)\n:::\n",
    "supporting": [
      "01-02-welcome_to_sl_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}