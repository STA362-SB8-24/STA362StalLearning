{
  "hash": "1437132cb5077740e186878c5713909e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lab 03\"\nsubtitle: \"Classification\"\nauthor: \"Emil Hvitfeldt modfied by {{< var instructor.name >}}\"\nformat: \n  html:\n    warning: false\n---\n\n\n# Getting started\n\nGo to our RStudio and create a new R project inside your class folder.\n\n## YAML: \n\nCreate a `.qmd` file for your lab, make sure the author is your name, and Render the document.\n\n\n# Packages\n\nIn this lab we will work with four packages: `ISLR` (and `ISLR2`) which are packages that accompany your textbook, `tidyverse` which is a collection of packages for doing data analysis in a \"tidy\" way, `tidymodels` a collection of packages for statistical modeling, `discrim` which has some of our models in it. \n\nThis chapter will use [parsnip](https://www.tidymodels.org/start/models/) for model fitting and [recipes and workflows](https://www.tidymodels.org/start/recipes/) to perform the transformations.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\nlibrary(ISLR) # For the Smarket data set\nlibrary(ISLR2) # For the Bikeshare data set\nlibrary(discrim)\n```\n:::\n\n\n## The Stock Market Data\n\nWe will be examining the `Smarket` data set for this lab. It contains a number of numeric variables plus a variable called `Direction` which has the two labels `\"Up\"` and `\"Down\"`. Before we do on to modeling, let us take a look at the correlation between the variables.\n\nTo look at the correlation, we will use the [corrr](https://corrr.tidymodels.org/) package. The `correlate()` function will calculate the correlation matrix between all the variables that it is being fed. We will therefore remove `Direction` as it is not numeric.\nThen we pass that to `rplot()` to quickly visualize the correlation matrix. I have also changed the `colours` argument to better see what is going on.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(corrr)\ncor_Smarket <- Smarket %>%\n  select(-Direction) %>%\n  correlate()\n\nrplot(cor_Smarket, colours = c(\"indianred2\", \"black\", \"skyblue1\"))\n```\n\n::: {.cell-output-display}\n![](03-classification_files/figure-html/unnamed-chunk-2-1.png){fig-alt='Correlation chart. Most values are very close to 0.\nYear and Volume appear quite correlated.' width=672}\n:::\n:::\n\n\nAnd we see that these variables are more or less uncorrelated with each other. The other pair is `Year` and `Volume` that is a little correlated.\n\nIf you want to create heatmap styled correlation chart you can also create it manually.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(paletteer)\ncor_Smarket %>%\n  stretch() %>%\n  ggplot(aes(x, y, fill = r)) +\n  geom_tile() +\n  geom_text(aes(label = as.character(fashion(r)))) +\n  scale_fill_paletteer_c(\"scico::roma\", limits = c(-1, 1), direction = -1)\n```\n\n::: {.cell-output-display}\n![](03-classification_files/figure-html/unnamed-chunk-3-1.png){fig-alt='Correlation chart. Most values are very close to 0.\nYear and Volume appear quite correlated.' width=672}\n:::\n:::\n\n\nIf we plot `Year` against `Volume` we see that there is an upwards trend in `Volume` with time.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(Smarket, aes(Year, Volume)) +\n  geom_jitter(height = 0)\n```\n\n::: {.cell-output-display}\n![](03-classification_files/figure-html/unnamed-chunk-4-1.png){fig-alt='Jittered scatter chart. Jittered around year along the\nx-axis. Volume along the y-axis. Fairly wide scattering\nalong volume. Slight increase in volumne as year increase.' width=672}\n:::\n:::\n\n\n\n## Exercises\n\n### Data Split\n\n1. Split the data into training and testing sets with 70% in the training set. \n\n### Answer the following in questions 2 through 6:\n    \na) Fit the model using Lag1-5 and volume to predict direction. \nb) What are the model assumptions? \nc) Check all of the assumptions.\nd) Assess your model on the testing set with accuracy, the ROC curve, and the ROC AUC and give the confusion matrix.\n\n2. Logistic Regression\nHINT: For linearity in logistic, you will need to create bins for each predictor, say 5 bins, then check the empirical probabilities for each bin.\n\n3. LDA\n\n4. QDA\n\n5. Naive Bayes\n\n6. K Nearest Neighbors\n\n### Comparing multiple models\n\nWe have fit a lot of different models in this lab. And we were able to calculate the performance metrics one by one, but it is not ideal if we want to compare the different models. Below is an example of how you can more conveniently calculate performance metrics for multiple models at the same time.\n\nStart of by creating a named list of the fitted models you want to evaluate. I have made sure only to include models that were fitted on the same parameters to make it easier to compare them.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodels <- list(\"logistic regression\" = lr_fit3,\n               \"LDA\" = lda_fit,\n               \"QDA\" = qda_fit,\n               \"KNN\" = knn_fit)\n```\n:::\n\n\nNext use `imap_dfr()` from the [purrr](https://purrr.tidyverse.org/) package to apply `augment()` to each of the models using the testing data set. `.id = \"model\"` creates a column named `\"model\"` that is added to the resulting tibble using the names of `models`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds <- imap_dfr(models, augment, \n                  new_data = Smarket_test, .id = \"model\")\n\npreds %>%\n  dplyr::select(model, Direction, .pred_class, .pred_Down, .pred_Up)\n```\n:::\n\n\nWe have seen how to use `accuracy()` a lot of times by now, but it is not the only metric to use for classification, and yardstick provides [many more](https://yardstick.tidymodels.org/reference/index.html#section-classification-metrics).\nYou can combine multiple different metrics together with `metric_set()`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmulti_metric <- metric_set(accuracy, sensitivity, specificity)\n```\n:::\n\n\nand then the resulting function can be applied to calculate multiple metrics at the same time. All of the yardstick works with grouped tibbles so by calling `group_by(model)` we can calculate the metrics for each of the models in one go.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds %>%\n  group_by(model) %>%\n  multi_metric(truth = Direction, estimate = .pred_class)\n```\n:::\n\n\nThe same technique can be used to create ROC curves.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds %>%\n  group_by(model) %>%\n  roc_curve(Direction, .pred_Down) %>%\n  autoplot()\n```\n:::\n\n\n7. Use the above code to fit all models as once and them compare them according to accuracy, ROC, and ROC AUC. ",
    "supporting": [
      "03-classification_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}